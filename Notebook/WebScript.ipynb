{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#已经安装的测试工具"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "antsword\n",
    "burpsuite\n",
    "msfconsole\n",
    "nmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Beautiful Soup使用\n",
    "\n",
    "import requests\n",
    "\n",
    "url = \"\"  # URL不变\n",
    "fake_headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36'\n",
    "}\n",
    "response = requests.get(url, headers=fake_headers)  \n",
    "print(response.content.decode('utf-8'))\n",
    "file_obj = open('testdir/test0.html', 'w')  \n",
    "file_obj.write(response.content.decode('utf-8'))  \n",
    "file_obj.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker search beef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get post请求\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS                                                                                                                              NAMES\ne3229d01e34f        centos              \"/bin/bash\"         27 seconds ago      Up 26 seconds              0.0.0.0:100->20/tcp, 0.0.0.0:101->21/tcp, 0.0.0.0:102->80/tcp, 0.0.0.0:103->443/tcp, 0.0.0.0:104->888/tcp, 0.0.0.0:105->8888/tcp   baota-centos\n0f705000e393        ubuntu              \"/bin/bash\"         51 minutes ago      Exited (0) 5 minutes ago                                                                                                                                      baota\n256b388719a7        dreamacro/clash     \"/clash\"            3 weeks ago         Up 4 days                  0.0.0.0:7890->7890/tcp, 0.0.0.0:9090->9090/tcp                                                                                     clash\n"
     ]
    }
   ],
   "source": [
    "!docker ps -a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dpkg –print-architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import os.path\n",
    " \n",
    "user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_11_5)'\n",
    "headers = {'User-Agent': user_agent}\n",
    " \n",
    "session = requests.session()\n",
    "page = session.get(\"http://www.xicidaili.com/nn/1\", headers=headers)\n",
    "soup = BeautifulSoup(page.text,'lxml')  #这里没有装lxml的话,把它去掉用默认的就好\n",
    " \n",
    "#匹配带有class属性的tr标签\n",
    "taglist = soup.find_all('tr', attrs={'class': re.compile(\"(odd)|()\")})\n",
    "for trtag in taglist:\n",
    "    tdlist = trtag.find_all('td')  #在每个tr标签下,查找所有的td标签\n",
    "    print (tdlist[1].string)   #这里提取IP值\n",
    "    print (tdlist[2].string)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url=\"https://www.bilibili.com/video/BV16K4y1p7dK?spm_id_from=333.851.b_7265636f6d6d656e64.1\"\n",
    "fake_headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; '\\\n",
    "'WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.79 Safari/537.36'\n",
    "}\n",
    "response = requests.get(url, headers=fake_headers)\n",
    "soup = BeautifulSoup(response.content.decode('utf-8'), 'lxml')\n",
    "videoview = soup.select('#viewbox_report > div > span.view')\n",
    "#videoview =videoview.get_text()\n",
    "#print(videoview)\n",
    "videoview=str(videoview)\n",
    "\n",
    "print(videoview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[index:index+15]"
   ]
  }
 ]
}